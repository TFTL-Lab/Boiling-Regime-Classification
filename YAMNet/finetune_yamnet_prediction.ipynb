{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-22 00:51:19.724885: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-22 00:51:20.549225: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-05-22 00:51:21.940491: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Imports.\n",
    "import os\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import matplotlib.pyplot as plt\n",
    "import params as yamnet_params\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import layers, regularizers \n",
    "import yamnet as yamnet_model\n",
    "import params as yamnet_params\n",
    "import features as features_lib\n",
    "import pandas as pd\n",
    "# Set random seed for TensorFlow\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-24 23:26:00.262675: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2025-03-24 23:26:00.262737: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:168] retrieving CUDA diagnostic information for host: user\n",
      "2025-03-24 23:26:00.262751: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:175] hostname: user\n",
      "2025-03-24 23:26:00.262973: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:199] libcuda reported version is: 535.183.1\n",
      "2025-03-24 23:26:00.263013: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:203] kernel reported version is: 535.183.1\n",
      "2025-03-24 23:26:00.263024: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:309] kernel version seems to match DSO: 535.183.1\n"
     ]
    }
   ],
   "source": [
    "import params as yamnet_params\n",
    "import features as features_lib\n",
    "import yamnet as yamnet_model\n",
    "sr = 10000\n",
    "params = yamnet_params.Params(sample_rate=sr, patch_hop_seconds=0.1)\n",
    "yamnet=yamnet_model.yamnet_frames_model(params)\n",
    "class_names = yamnet_model.class_names('yamnet_class_map_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error setting weights for layer dense_1: No such layer: dense_1. Existing layers are: ['input_1', 'tf.reshape', 'input_2', 'layer1/conv', 'layer1/conv/bn', 'layer1/relu', 'layer2/depthwise_conv', 'layer2/depthwise_conv/bn', 'layer2/depthwise_conv/relu', 'layer2/pointwise_conv', 'layer2/pointwise_conv/bn', 'layer2/pointwise_conv/relu', 'layer3/depthwise_conv', 'layer3/depthwise_conv/bn', 'layer3/depthwise_conv/relu', 'layer3/pointwise_conv', 'layer3/pointwise_conv/bn', 'layer3/pointwise_conv/relu', 'layer4/depthwise_conv', 'layer4/depthwise_conv/bn', 'layer4/depthwise_conv/relu', 'layer4/pointwise_conv', 'layer4/pointwise_conv/bn', 'layer4/pointwise_conv/relu', 'layer5/depthwise_conv', 'layer5/depthwise_conv/bn', 'layer5/depthwise_conv/relu', 'layer5/pointwise_conv', 'layer5/pointwise_conv/bn', 'layer5/pointwise_conv/relu', 'layer6/depthwise_conv', 'layer6/depthwise_conv/bn', 'layer6/depthwise_conv/relu', 'layer6/pointwise_conv', 'layer6/pointwise_conv/bn', 'layer6/pointwise_conv/relu', 'layer7/depthwise_conv', 'layer7/depthwise_conv/bn', 'layer7/depthwise_conv/relu', 'layer7/pointwise_conv', 'layer7/pointwise_conv/bn', 'layer7/pointwise_conv/relu', 'layer8/depthwise_conv', 'layer8/depthwise_conv/bn', 'layer8/depthwise_conv/relu', 'layer8/pointwise_conv', 'layer8/pointwise_conv/bn', 'layer8/pointwise_conv/relu', 'layer9/depthwise_conv', 'layer9/depthwise_conv/bn', 'layer9/depthwise_conv/relu', 'layer9/pointwise_conv', 'layer9/pointwise_conv/bn', 'layer9/pointwise_conv/relu', 'layer10/depthwise_conv', 'layer10/depthwise_conv/bn', 'layer10/depthwise_conv/relu', 'layer10/pointwise_conv', 'layer10/pointwise_conv/bn', 'layer10/pointwise_conv/relu', 'layer11/depthwise_conv', 'layer11/depthwise_conv/bn', 'layer11/depthwise_conv/relu', 'layer11/pointwise_conv', 'layer11/pointwise_conv/bn', 'layer11/pointwise_conv/relu', 'layer12/depthwise_conv', 'layer12/depthwise_conv/bn', 'layer12/depthwise_conv/relu', 'layer12/pointwise_conv', 'layer12/pointwise_conv/bn', 'layer12/pointwise_conv/relu', 'layer13/depthwise_conv', 'layer13/depthwise_conv/bn', 'layer13/depthwise_conv/relu', 'layer13/pointwise_conv', 'layer13/pointwise_conv/bn', 'layer13/pointwise_conv/relu', 'layer14/depthwise_conv', 'layer14/depthwise_conv/bn', 'layer14/depthwise_conv/relu', 'layer14/pointwise_conv', 'layer14/pointwise_conv/bn', 'layer14/pointwise_conv/relu', 'global_average_pooling2d', 'dense', 'activation'].\n",
      "Model output has changed after loading weights.\n"
     ]
    }
   ],
   "source": [
    "#load pre-trained weights \n",
    "import tensorflow as tf\n",
    "# Create a dummy input\n",
    "dummy_input = tf.random.normal([1, 103,98])\n",
    "\n",
    "# Get output before loading weights\n",
    "output_before = yamnet(dummy_input)\n",
    "\n",
    "layer_to_skip = 'dense_1'  # Replace with the actual layer name\n",
    "\n",
    "# Load weights for all layers\n",
    "try:\n",
    "    yamnet.load_weights('yamnet_ndata.h5', by_name=True)\n",
    "except Exception as e:\n",
    "    print(f\"Error loading weights: {e}\")\n",
    "\n",
    "# Manually handle the problematic layer\n",
    "try:\n",
    "    layer = yamnet.get_layer(name=layer_to_skip)\n",
    "    # Optionally set weights to some default values or random\n",
    "    layer.set_weights([np.random.randn(*w.shape) for w in layer.weights])\n",
    "except Exception as e:\n",
    "    print(f\"Error setting weights for layer {layer_to_skip}: {e}\")\n",
    "\n",
    "# Get output after loading weights\n",
    "output_after = yamnet(dummy_input)\n",
    "\n",
    "# Compare outputs\n",
    "if not np.allclose(output_before.numpy(), output_after.numpy()):\n",
    "    print(\"Model output has changed after loading weights.\")\n",
    "else:\n",
    "    print(\"Model output has not changed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all layers\n",
    "for layer in yamnet.layers:\n",
    "    layer.trainable = False\n",
    "for i, layer in enumerate(yamnet.layers):\n",
    "    if 'layer13' in layer.name or 'layer14' in layer.name:\n",
    "        layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy.io.wavfile as wav\n",
    "from scipy import signal\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from scipy.signal import spectrogram\n",
    "\n",
    "np.random.seed(42)\n",
    "# Specify the folder name\n",
    "dataset_folder = '/DATA-CRPS/Audio_Files_and_MatLab_Code_used_for_Advance_Prediction_of_CHF/Audio_files'\n",
    "\n",
    "# Create a list of audio files with labels\n",
    "commands = [\"BKG\", \"NB\",\"TB\"]\n",
    "audio_files = []\n",
    "labels = []\n",
    "\n",
    "for root, _, files in os.walk(dataset_folder):\n",
    "    for file in files:\n",
    "        if file.endswith('.wav'):\n",
    "            label = os.path.basename(root)\n",
    "            if label in commands:\n",
    "                audio_files.append(os.path.join(root, file))\n",
    "                labels.append(label)\n",
    "\n",
    "# Shuffle and partition the data into training, validation, and testing sets\n",
    "indices = np.random.permutation(len(audio_files))\n",
    "\n",
    "n_files = len(audio_files)\n",
    "n_valid = n_files // 5\n",
    "n_test = n_files // 5\n",
    "\n",
    "valid_indices = indices[:n_valid]\n",
    "test_indices = indices[n_valid:n_valid + n_test]\n",
    "train_indices = indices[n_valid + n_test:]\n",
    "\n",
    "audio_files_valid = [audio_files[i] for i in valid_indices]\n",
    "audio_files_test = [audio_files[i] for i in test_indices]\n",
    "audio_files_train = [audio_files[i] for i in train_indices]\n",
    "\n",
    "valid_labels = [labels[i] for i in valid_indices]\n",
    "test_labels = [labels[i] for i in test_indices]\n",
    "train_labels = [labels[i] for i in train_indices]\n",
    "\n",
    "# Audio Feature Extraction\n",
    "fs = 10000  # Known sample rate of the data set\n",
    "segment_duration = 1\n",
    "frame_duration = 0.025\n",
    "hop_duration = 0.010\n",
    "fft_size=512\n",
    "segment_samples = int(segment_duration * fs)\n",
    "frame_samples = int(frame_duration * fs)\n",
    "hop_samples = int(hop_duration * fs)\n",
    "min_frequency = 0\n",
    "max_frequency = 2000\n",
    "\n",
    "# Function to extract features from an audio file\n",
    "def extract_features(file):\n",
    "    sample_rate, y = wav.read(file)\n",
    "    f, t, Zxx = spectrogram(y, fs=fs, nperseg=frame_samples, noverlap=frame_samples-hop_samples,nfft = 512)#window='hann'\n",
    "    freq_mask = (f >= min_frequency) & (f <= max_frequency)\n",
    "    freq_mask2 = (f >= 0) & (f <= 50)\n",
    "    linear_spectrum_db = Zxx.astype(float) #np.abs(Zxx.astype(float))\n",
    "    # linear_spectrum_db[freq_mask2, : ] = 0\n",
    "    linear_spectrum_db = linear_spectrum_db[freq_mask, : ]\n",
    "    \n",
    "    # linear_spectrum_db = np.log10(np.abs(Zxx)+1e-6)[freq_mask, : ]\n",
    "    return linear_spectrum_db[..., np.newaxis]\n",
    "\n",
    "# Extract features in parallel\n",
    "def process_files(file_list):\n",
    "    features_list = [extract_features(file) for file in file_list]\n",
    "    return features_list\n",
    "features = extract_features(audio_files_train[0])\n",
    "print(features.shape)\n",
    "[num_hops, num_features,_] = features.shape\n",
    "print(num_hops,num_features)\n",
    "\n",
    "train_features = np.zeros((len(audio_files_train),num_hops,num_features,1))\n",
    "valid_features = np.zeros((len(audio_files_valid),num_hops,num_features,1))\n",
    "test_features = np.zeros((len(audio_files_test),num_hops,num_features,1))\n",
    "\n",
    "# Parallel processing\n",
    "num_workers =  10 # Number of workers should not exceed the number of files\n",
    "with ProcessPoolExecutor(max_workers=num_workers) as executor:\n",
    "    train_features_list = list(executor.map(extract_features, audio_files_train))\n",
    "    valid_features_list = list(executor.map(extract_features, audio_files_valid))\n",
    "    test_features_list = list(executor.map(extract_features, audio_files_test))\n",
    "\n",
    "for idx, features in enumerate(train_features_list):\n",
    "    train_features[idx,:, :, :] = features\n",
    "\n",
    "for id, features in enumerate(valid_features_list):\n",
    "    valid_features[id,:, :, :] = features\n",
    "\n",
    "for i, features in enumerate(test_features_list):\n",
    "    test_features[i,:, :, :] = features\n",
    "\n",
    "\n",
    "# Normalization\n",
    "un_norm = 2 / (np.sum(signal.windows.hann(frame_samples, sym=False))**2)\n",
    "\n",
    "train_features /= un_norm\n",
    "valid_features /= un_norm\n",
    "test_features /= un_norm\n",
    "\n",
    "epsil = 1e-6\n",
    "train_features = np.log10(train_features + epsil)\n",
    "valid_features = np.log10(valid_features + epsil)\n",
    "test_features = np.log10(test_features + epsil)\n",
    "\n",
    "print(\"Training features shape:\", train_features.shape)\n",
    "print(\"Validation features shape:\", valid_features.shape)\n",
    "print(\"Testing features shape:\", test_features.shape)\n",
    "\n",
    "label_map = {label: idx for idx, label in enumerate(commands)}\n",
    "train_labels_cat = to_categorical([label_map[label] for label in train_labels])\n",
    "valid_labels_cat = to_categorical([label_map[label] for label in valid_labels])\n",
    "test_labels_cat = to_categorical([label_map[label] for label in test_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping,Callback\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "seed_value = 42\n",
    "tf.random.set_seed(seed_value)\n",
    "# Compute class weights\n",
    "train_labels_numeric = np.argmax(train_labels_cat, axis=1)\n",
    "class_weights_array = compute_class_weight('balanced', classes=np.unique(train_labels_numeric), y=train_labels_numeric)\n",
    "class_weights = dict(enumerate(class_weights_array))\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=15, restore_best_weights=True, mode='max')\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "yamnet.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=optimizer)\n",
    "\n",
    "\n",
    "epochs = 25\n",
    "batch_size = 128\n",
    "history = yamnet.fit(train_features, train_labels_cat,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    validation_data=(valid_features, valid_labels_cat),\n",
    "                    class_weight=class_weights,\n",
    "                    callbacks=[early_stopping],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "# Evaluate the model on training data\n",
    "train_loss, train_accuracy = yamnet.evaluate(valid_features, valid_labels_cat, verbose=1)\n",
    "print(f\"Val loss: {train_loss:.4f}\")\n",
    "print(f\"Val accuracy: {train_accuracy:.4f}\")\n",
    "train_loss, train_accuracy = yamnet.evaluate(test_features, test_labels_cat, verbose=1)\n",
    "print(f\"TEst loss: {train_loss:.4f}\")\n",
    "print(f\"TEst accuracy: {train_accuracy:.4f}\")\n",
    "test_pred = np.argmax(yamnet.predict(test_features), axis=1)\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(np.argmax(test_labels_cat, axis=1), test_pred)\n",
    "labels= ['BKG','NB','TB']\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "# Plot the confusion matrix\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "# Customizing font size\n",
    "disp.plot(ax=ax, cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix for Validation Data', fontsize=16)\n",
    "plt.xlabel('Predicted labels', fontsize=18)\n",
    "plt.ylabel('True labels', fontsize=18)\n",
    "# Increase font size for ticks\n",
    "ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "\n",
    "# Increase font size for numbers in the matrix\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        # Adjust the text position and size to avoid overlap\n",
    "        value = cm[i, j]\n",
    "        ax.text(j, i, f'{value}', ha='center', va='center', fontsize=14, color='black', fontweight='bold', bbox=dict(facecolor='lightblue', alpha=0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Compute core data\n",
    "cm = confusion_matrix(train_labels_class, train_pred)\n",
    "report = classification_report(train_labels_class, train_pred, target_names=commands, output_dict=True)\n",
    "classes = commands\n",
    "n = len(classes)\n",
    "\n",
    "# Extract per-class metrics\n",
    "precision = [report[c]['precision'] for c in classes]\n",
    "recall = [report[c]['recall'] for c in classes]\n",
    "f1 = [report[c]['f1-score'] for c in classes]\n",
    "accuracy_per_class = cm.diagonal() / cm.sum(axis=1)\n",
    "\n",
    "# Create a padded matrix with 2 extra rows and 2 extra columns\n",
    "# Layout: (top row for F1, bottom row for accuracy)\n",
    "#         (left column for precision, right for accuracy per class)\n",
    "full_matrix = np.full((n + 2, n + 2), '', dtype=object)\n",
    "\n",
    "# Insert confusion matrix into center (only this part will be visualized as a heatmap)\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        full_matrix[i + 1, j + 1] = cm[i, j]\n",
    "\n",
    "\n",
    "# Labels for axes\n",
    "xtick_labels = [''] + classes + ['']\n",
    "ytick_labels = [''] + classes + ['']\n",
    "\n",
    "# Plot the confusion matrix with a heatmap\n",
    "plt.figure(figsize=(4, 3))\n",
    "fontsize = 11\n",
    "ax = sns.heatmap(cm, annot=True, fmt='d', cmap=\"Purples\", cbar=False, cbar_kws={'label': 'Count'},annot_kws={\"size\": fontsize},\n",
    "                 xticklabels=classes, yticklabels=classes, linewidths=0.5, square=True)\n",
    "ax.tick_params(axis='both', which='both', length=0)\n",
    "ax.tick_params(axis='y', pad=17)\n",
    "ax.tick_params(axis='x', pad=16)\n",
    "# plt.ylabel(\" True\", \n",
    "#            fontsize=12, \n",
    "#            color='white',\n",
    "#            bbox=dict(facecolor='green', edgecolor='none', boxstyle='round,pad=0.2'))\n",
    "\n",
    "# plt.xlabel(\"Predicted\", \n",
    "#            fontsize=12, \n",
    "#            bbox=dict(facecolor='red', edgecolor='none', boxstyle='round,pad=0.2'), \n",
    "#            color='white')\n",
    "\n",
    "\n",
    "\n",
    "# # Add the precision, recall, F1, and accuracy annotations around the matrix\n",
    "for j in range(n):\n",
    "    ax.text(j + 0.5, -0.1, f\"F1: {f1[j]:.2f}\", ha='center', va='center', fontsize=11, color='black')\n",
    "    \n",
    "for j in range(n):  # Known sample rate of the data set\n",
    "    ax.text(j + 0.5, n + 0, f\"A: {accuracy_per_class[j]:.2f}\", ha='center', va='center', fontsize=11, color='black')\n",
    "\n",
    "for i in range(n):\n",
    "    ax.text(-0.1, i + 0.5, f\"P: {precision[i]:.2f}\", ha='center', va='center', fontsize=11, color='black',rotation=90)\n",
    "\n",
    "for i in range(n):\n",
    "    ax.text(n + 0.1, i + 0.5, f\"R: {recall[i]:.2f}\", ha='center', va='center', fontsize=11, color='black',rotation=90)\n",
    "\n",
    "# Add titles and labels\n",
    "# plt.title(\"Confusion Matrix with Precision (Left), Recall (Right), F1 (Top), Accuracy (Bottom)\")\n",
    "plt.xticks(rotation=0,fontsize=11)\n",
    "plt.yticks(rotation=90,fontsize=11)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
